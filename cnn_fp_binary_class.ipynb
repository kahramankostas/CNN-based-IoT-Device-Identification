{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "input_shape = (5, 5, 1)\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "#(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "#%matplotlib inline # Only use this if using iPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(x):\n",
    "    df=pd.read_csv(\"hybrid.csv\") \n",
    "    df_1= df[df['Label']==(x)]\n",
    "    df_0= df[df['Label']!=(x)]\n",
    "    if x==16:\n",
    "        t=2\n",
    "    elif x==15:\n",
    "        t=2#1.5\n",
    "    else:\n",
    "        t=10\n",
    "    df_0 = df_0.sample(n=int(len(df_1)*t))\n",
    "    result = pd.concat([df_1,df_0])\n",
    "    result=result.reindex(np.random.permutation(result.index))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5772 5772\n",
      "Epoch 1/10\n",
      "4329/4329 [==============================] - 1s 145us/step - loss: 1.0449 - acc: 0.8053\n",
      "Epoch 2/10\n",
      "4329/4329 [==============================] - 0s 66us/step - loss: 0.4101 - acc: 0.8450\n",
      "Epoch 3/10\n",
      "4329/4329 [==============================] - 0s 65us/step - loss: 0.3788 - acc: 0.8533\n",
      "Epoch 4/10\n",
      "4329/4329 [==============================] - 0s 66us/step - loss: 0.3598 - acc: 0.8517\n",
      "Epoch 5/10\n",
      "4329/4329 [==============================] - 0s 70us/step - loss: 0.3338 - acc: 0.8568\n",
      "Epoch 6/10\n",
      "4329/4329 [==============================] - 0s 70us/step - loss: 0.3116 - acc: 0.8600\n",
      "Epoch 7/10\n",
      "4329/4329 [==============================] - 0s 65us/step - loss: 0.2948 - acc: 0.8545\n",
      "Epoch 8/10\n",
      "4329/4329 [==============================] - 0s 64us/step - loss: 0.2718 - acc: 0.8642\n",
      "Epoch 9/10\n",
      "4329/4329 [==============================] - 0s 65us/step - loss: 0.2621 - acc: 0.8623\n",
      "Epoch 10/10\n",
      "4329/4329 [==============================] - 0s 64us/step - loss: 0.2541 - acc: 0.8672\n",
      "1443/1443 [==============================] - 0s 103us/step\n",
      "44844 44844\n",
      "Epoch 1/10\n",
      "33633/33633 [==============================] - 2s 74us/step - loss: 0.4303 - acc: 0.8511\n",
      "Epoch 2/10\n",
      "33633/33633 [==============================] - 2s 64us/step - loss: 0.3067 - acc: 0.8744\n",
      "Epoch 3/10\n",
      "33633/33633 [==============================] - 2s 64us/step - loss: 0.3044 - acc: 0.8754\n",
      "Epoch 4/10\n",
      "33633/33633 [==============================] - 2s 65us/step - loss: 0.3010 - acc: 0.8771\n",
      "Epoch 5/10\n",
      "33633/33633 [==============================] - 2s 66us/step - loss: 0.2985 - acc: 0.8781\n",
      "Epoch 6/10\n",
      "33633/33633 [==============================] - 2s 65us/step - loss: 0.2944 - acc: 0.8807\n",
      "Epoch 7/10\n",
      "33633/33633 [==============================] - 2s 65us/step - loss: 0.2894 - acc: 0.8825\n",
      "Epoch 8/10\n",
      "33633/33633 [==============================] - 2s 66us/step - loss: 0.2818 - acc: 0.8872\n",
      "Epoch 9/10\n",
      "33633/33633 [==============================] - 2s 65us/step - loss: 0.2728 - acc: 0.8908\n",
      "Epoch 10/10\n",
      "33633/33633 [==============================] - 2s 63us/step - loss: 0.2609 - acc: 0.8959\n",
      "11211/11211 [==============================] - 0s 42us/step\n",
      "7044 7044\n",
      "Epoch 1/10\n",
      "5283/5283 [==============================] - 1s 135us/step - loss: 0.9612 - acc: 0.8130\n",
      "Epoch 2/10\n",
      "5283/5283 [==============================] - 0s 66us/step - loss: 0.2882 - acc: 0.8472\n",
      "Epoch 3/10\n",
      "5283/5283 [==============================] - 0s 69us/step - loss: 0.2550 - acc: 0.8539\n",
      "Epoch 4/10\n",
      "5283/5283 [==============================] - 0s 71us/step - loss: 0.2453 - acc: 0.8611\n",
      "Epoch 5/10\n",
      "5283/5283 [==============================] - 0s 65us/step - loss: 0.2371 - acc: 0.8635\n",
      "Epoch 6/10\n",
      "5283/5283 [==============================] - 0s 67us/step - loss: 0.2279 - acc: 0.8728\n",
      "Epoch 7/10\n",
      "5283/5283 [==============================] - 0s 73us/step - loss: 0.2178 - acc: 0.8753\n",
      "Epoch 8/10\n",
      "5283/5283 [==============================] - 0s 73us/step - loss: 0.2072 - acc: 0.8900\n",
      "Epoch 9/10\n",
      "5283/5283 [==============================] - 0s 73us/step - loss: 0.1938 - acc: 0.9019\n",
      "Epoch 10/10\n",
      "5283/5283 [==============================] - 0s 70us/step - loss: 0.1809 - acc: 0.9114: 0s - loss: 0.1841 - acc: 0\n",
      "1761/1761 [==============================] - 0s 111us/step\n",
      "22776 22776\n",
      "Epoch 1/10\n",
      "17082/17082 [==============================] - 2s 89us/step - loss: 0.4533 - acc: 0.8738\n",
      "Epoch 2/10\n",
      "17082/17082 [==============================] - 1s 72us/step - loss: 0.1000 - acc: 0.9796\n",
      "Epoch 3/10\n",
      "17082/17082 [==============================] - 1s 80us/step - loss: 0.0487 - acc: 0.9912\n",
      "Epoch 4/10\n",
      "17082/17082 [==============================] - 2s 94us/step - loss: 0.0390 - acc: 0.9914: 1s - loss: \n",
      "Epoch 5/10\n",
      "17082/17082 [==============================] - 1s 79us/step - loss: 0.0363 - acc: 0.9911\n",
      "Epoch 6/10\n",
      "17082/17082 [==============================] - 1s 68us/step - loss: 0.0354 - acc: 0.9907\n",
      "Epoch 7/10\n",
      "17082/17082 [==============================] - 1s 77us/step - loss: 0.0342 - acc: 0.9907\n",
      "Epoch 8/10\n",
      "17082/17082 [==============================] - 1s 71us/step - loss: 0.0334 - acc: 0.9917\n",
      "Epoch 9/10\n",
      "17082/17082 [==============================] - 1s 66us/step - loss: 0.0332 - acc: 0.9914\n",
      "Epoch 10/10\n",
      "17082/17082 [==============================] - 1s 65us/step - loss: 0.0330 - acc: 0.9908\n",
      "5694/5694 [==============================] - 0s 62us/step\n",
      "95268 95268\n",
      "Epoch 1/10\n",
      "71451/71451 [==============================] - 6s 90us/step - loss: 0.4423 - acc: 0.8392\n",
      "Epoch 2/10\n",
      "71451/71451 [==============================] - 6s 79us/step - loss: 0.3489 - acc: 0.8491\n",
      "Epoch 3/10\n",
      "71451/71451 [==============================] - 5s 72us/step - loss: 0.3348 - acc: 0.8550\n",
      "Epoch 4/10\n",
      "71451/71451 [==============================] - 5s 65us/step - loss: 0.3220 - acc: 0.8651\n",
      "Epoch 5/10\n",
      "71451/71451 [==============================] - 4s 62us/step - loss: 0.3070 - acc: 0.8774\n",
      "Epoch 6/10\n",
      "71451/71451 [==============================] - 4s 62us/step - loss: 0.2964 - acc: 0.8831\n",
      "Epoch 7/10\n",
      "71451/71451 [==============================] - 5s 68us/step - loss: 0.2895 - acc: 0.8857\n",
      "Epoch 8/10\n",
      "71451/71451 [==============================] - 7s 100us/step - loss: 0.2852 - acc: 0.8878\n",
      "Epoch 9/10\n",
      "71451/71451 [==============================] - 8s 107us/step - loss: 0.2825 - acc: 0.8886\n",
      "Epoch 10/10\n",
      "71451/71451 [==============================] - 8s 107us/step - loss: 0.2787 - acc: 0.8900\n",
      "23817/23817 [==============================] - 2s 76us/step\n",
      "76146 76146\n",
      "Epoch 1/10\n",
      "57109/57109 [==============================] - 7s 128us/step - loss: 0.4852 - acc: 0.8316\n",
      "Epoch 2/10\n",
      "57109/57109 [==============================] - 6s 110us/step - loss: 0.4084 - acc: 0.8337\n",
      "Epoch 3/10\n",
      "57109/57109 [==============================] - 6s 106us/step - loss: 0.3856 - acc: 0.8337\n",
      "Epoch 4/10\n",
      "57109/57109 [==============================] - 6s 104us/step - loss: 0.3684 - acc: 0.8336\n",
      "Epoch 5/10\n",
      "57109/57109 [==============================] - 6s 102us/step - loss: 0.3495 - acc: 0.8332\n",
      "Epoch 6/10\n",
      "57109/57109 [==============================] - 6s 102us/step - loss: 0.3378 - acc: 0.8331\n",
      "Epoch 7/10\n",
      "57109/57109 [==============================] - 6s 103us/step - loss: 0.3301 - acc: 0.8328\n",
      "Epoch 8/10\n",
      "57109/57109 [==============================] - 6s 103us/step - loss: 0.3258 - acc: 0.8321\n",
      "Epoch 9/10\n",
      "57109/57109 [==============================] - 6s 101us/step - loss: 0.3217 - acc: 0.8330\n",
      "Epoch 10/10\n",
      "57109/57109 [==============================] - 6s 105us/step - loss: 0.3200 - acc: 0.8331\n",
      "19037/19037 [==============================] - 2s 95us/step\n",
      "70878 70878\n",
      "Epoch 1/10\n",
      "53158/53158 [==============================] - 7s 125us/step - loss: 0.4934 - acc: 0.8303\n",
      "Epoch 2/10\n",
      "53158/53158 [==============================] - 6s 106us/step - loss: 0.4036 - acc: 0.8343\n",
      "Epoch 3/10\n",
      "53158/53158 [==============================] - 6s 116us/step - loss: 0.3858 - acc: 0.8343\n",
      "Epoch 4/10\n",
      "53158/53158 [==============================] - 6s 105us/step - loss: 0.3732 - acc: 0.8344\n",
      "Epoch 5/10\n",
      "53158/53158 [==============================] - 6s 105us/step - loss: 0.3640 - acc: 0.8342\n",
      "Epoch 6/10\n",
      "53158/53158 [==============================] - 6s 105us/step - loss: 0.3538 - acc: 0.8337\n",
      "Epoch 7/10\n",
      "53158/53158 [==============================] - 5s 102us/step - loss: 0.3472 - acc: 0.8329\n",
      "Epoch 8/10\n",
      "53158/53158 [==============================] - 4s 79us/step - loss: 0.3384 - acc: 0.8336\n",
      "Epoch 9/10\n",
      "53158/53158 [==============================] - 4s 70us/step - loss: 0.3322 - acc: 0.8325\n",
      "Epoch 10/10\n",
      "53158/53158 [==============================] - 4s 70us/step - loss: 0.3263 - acc: 0.8331\n",
      "17720/17720 [==============================] - 1s 49us/step\n",
      "77700 77700\n",
      "Epoch 1/10\n",
      "58275/58275 [==============================] - 5s 79us/step - loss: 0.4689 - acc: 0.8301\n",
      "Epoch 2/10\n",
      "58275/58275 [==============================] - 4s 72us/step - loss: 0.3866 - acc: 0.8315\n",
      "Epoch 3/10\n",
      "58275/58275 [==============================] - 4s 74us/step - loss: 0.3757 - acc: 0.8317\n",
      "Epoch 4/10\n",
      "58275/58275 [==============================] - 4s 73us/step - loss: 0.3690 - acc: 0.8312\n",
      "Epoch 5/10\n",
      "58275/58275 [==============================] - 4s 68us/step - loss: 0.3626 - acc: 0.8309\n",
      "Epoch 6/10\n",
      "58275/58275 [==============================] - 4s 68us/step - loss: 0.3552 - acc: 0.8305\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58275/58275 [==============================] - 4s 68us/step - loss: 0.3475 - acc: 0.8303\n",
      "Epoch 8/10\n",
      "58275/58275 [==============================] - 4s 69us/step - loss: 0.3412 - acc: 0.8302\n",
      "Epoch 9/10\n",
      "58275/58275 [==============================] - 4s 69us/step - loss: 0.3379 - acc: 0.8316\n",
      "Epoch 10/10\n",
      "58275/58275 [==============================] - 4s 70us/step - loss: 0.3353 - acc: 0.8322\n",
      "19425/19425 [==============================] - 1s 43us/step\n",
      "72588 72588\n",
      "Epoch 1/10\n",
      "54441/54441 [==============================] - 5s 86us/step - loss: 0.4838 - acc: 0.8299\n",
      "Epoch 2/10\n",
      "54441/54441 [==============================] - 4s 69us/step - loss: 0.3992 - acc: 0.8327\n",
      "Epoch 3/10\n",
      "54441/54441 [==============================] - 5s 99us/step - loss: 0.3843 - acc: 0.8326\n",
      "Epoch 4/10\n",
      "54441/54441 [==============================] - 6s 108us/step - loss: 0.3692 - acc: 0.8325\n",
      "Epoch 5/10\n",
      "54441/54441 [==============================] - 5s 87us/step - loss: 0.3522 - acc: 0.8323\n",
      "Epoch 6/10\n",
      "54441/54441 [==============================] - 4s 67us/step - loss: 0.3416 - acc: 0.8314\n",
      "Epoch 7/10\n",
      "54441/54441 [==============================] - 4s 71us/step - loss: 0.3340 - acc: 0.8331\n",
      "Epoch 8/10\n",
      "54441/54441 [==============================] - 4s 71us/step - loss: 0.3303 - acc: 0.8340\n",
      "Epoch 9/10\n",
      "54441/54441 [==============================] - 4s 69us/step - loss: 0.3278 - acc: 0.8345\n",
      "Epoch 10/10\n",
      "54441/54441 [==============================] - 4s 67us/step - loss: 0.3261 - acc: 0.8350\n",
      "18147/18147 [==============================] - 1s 41us/step\n",
      "5376 5376\n",
      "Epoch 1/10\n",
      "4032/4032 [==============================] - 1s 214us/step - loss: 1.0158 - acc: 0.8229\n",
      "Epoch 2/10\n",
      "4032/4032 [==============================] - 0s 63us/step - loss: 0.2441 - acc: 0.8896\n",
      "Epoch 3/10\n",
      "4032/4032 [==============================] - 0s 71us/step - loss: 0.2175 - acc: 0.8991\n",
      "Epoch 4/10\n",
      "4032/4032 [==============================] - 0s 69us/step - loss: 0.2065 - acc: 0.8981\n",
      "Epoch 5/10\n",
      "4032/4032 [==============================] - 0s 73us/step - loss: 0.2022 - acc: 0.8953\n",
      "Epoch 6/10\n",
      "4032/4032 [==============================] - 0s 70us/step - loss: 0.1946 - acc: 0.8983\n",
      "Epoch 7/10\n",
      "4032/4032 [==============================] - 0s 66us/step - loss: 0.1900 - acc: 0.8988\n",
      "Epoch 8/10\n",
      "4032/4032 [==============================] - 0s 102us/step - loss: 0.1855 - acc: 0.9060\n",
      "Epoch 9/10\n",
      "4032/4032 [==============================] - 0s 109us/step - loss: 0.1852 - acc: 0.9045\n",
      "Epoch 10/10\n",
      "4032/4032 [==============================] - 0s 77us/step - loss: 0.1784 - acc: 0.9132\n",
      "1344/1344 [==============================] - 0s 249us/step\n",
      "10656 10656\n",
      "Epoch 1/10\n",
      "7992/7992 [==============================] - 1s 147us/step - loss: 0.7479 - acc: 0.8267\n",
      "Epoch 2/10\n",
      "7992/7992 [==============================] - 0s 62us/step - loss: 0.3995 - acc: 0.8336\n",
      "Epoch 3/10\n",
      "7992/7992 [==============================] - 1s 64us/step - loss: 0.3797 - acc: 0.8311\n",
      "Epoch 4/10\n",
      "7992/7992 [==============================] - 1s 75us/step - loss: 0.3702 - acc: 0.8310\n",
      "Epoch 5/10\n",
      "7992/7992 [==============================] - 1s 79us/step - loss: 0.3579 - acc: 0.8347\n",
      "Epoch 6/10\n",
      "7992/7992 [==============================] - 1s 83us/step - loss: 0.3536 - acc: 0.8322\n",
      "Epoch 7/10\n",
      "7992/7992 [==============================] - 1s 83us/step - loss: 0.3497 - acc: 0.8365\n",
      "Epoch 8/10\n",
      "7992/7992 [==============================] - 1s 76us/step - loss: 0.3455 - acc: 0.8332\n",
      "Epoch 9/10\n",
      "7992/7992 [==============================] - 1s 69us/step - loss: 0.3389 - acc: 0.8365\n",
      "Epoch 10/10\n",
      "7992/7992 [==============================] - 1s 68us/step - loss: 0.3337 - acc: 0.8337\n",
      "2664/2664 [==============================] - 0s 113us/step\n",
      "9942 9942\n",
      "Epoch 1/10\n",
      "7456/7456 [==============================] - 1s 144us/step - loss: 0.8320 - acc: 0.8196\n",
      "Epoch 2/10\n",
      "7456/7456 [==============================] - 1s 71us/step - loss: 0.3832 - acc: 0.8345\n",
      "Epoch 3/10\n",
      "7456/7456 [==============================] - 1s 72us/step - loss: 0.3542 - acc: 0.8412\n",
      "Epoch 4/10\n",
      "7456/7456 [==============================] - 1s 76us/step - loss: 0.3352 - acc: 0.8510\n",
      "Epoch 5/10\n",
      "7456/7456 [==============================] - 1s 76us/step - loss: 0.3287 - acc: 0.8521\n",
      "Epoch 6/10\n",
      "7456/7456 [==============================] - 1s 71us/step - loss: 0.3208 - acc: 0.8573\n",
      "Epoch 7/10\n",
      "7456/7456 [==============================] - 1s 73us/step - loss: 0.3194 - acc: 0.8547\n",
      "Epoch 8/10\n",
      "7456/7456 [==============================] - 1s 74us/step - loss: 0.3140 - acc: 0.8561\n",
      "Epoch 9/10\n",
      "7456/7456 [==============================] - 1s 75us/step - loss: 0.3124 - acc: 0.8522\n",
      "Epoch 10/10\n",
      "7456/7456 [==============================] - 1s 72us/step - loss: 0.3089 - acc: 0.8568\n",
      "2486/2486 [==============================] - 0s 126us/step\n",
      "2718 2718\n",
      "Epoch 1/10\n",
      "2038/2038 [==============================] - 1s 368us/step - loss: 1.8742 - acc: 0.7605\n",
      "Epoch 2/10\n",
      "2038/2038 [==============================] - 0s 101us/step - loss: 0.3902 - acc: 0.8356\n",
      "Epoch 3/10\n",
      "2038/2038 [==============================] - 0s 110us/step - loss: 0.2962 - acc: 0.8528\n",
      "Epoch 4/10\n",
      "2038/2038 [==============================] - 0s 81us/step - loss: 0.2557 - acc: 0.8543\n",
      "Epoch 5/10\n",
      "2038/2038 [==============================] - 0s 73us/step - loss: 0.2240 - acc: 0.8710\n",
      "Epoch 6/10\n",
      "2038/2038 [==============================] - 0s 82us/step - loss: 0.1988 - acc: 0.8876\n",
      "Epoch 7/10\n",
      "2038/2038 [==============================] - 0s 76us/step - loss: 0.1901 - acc: 0.8930\n",
      "Epoch 8/10\n",
      "2038/2038 [==============================] - 0s 74us/step - loss: 0.1829 - acc: 0.9043\n",
      "Epoch 9/10\n",
      "2038/2038 [==============================] - 0s 76us/step - loss: 0.1757 - acc: 0.9141\n",
      "Epoch 10/10\n",
      "2038/2038 [==============================] - 0s 74us/step - loss: 0.1739 - acc: 0.9082\n",
      "680/680 [==============================] - 0s 378us/step\n",
      "8550 8550\n",
      "Epoch 1/10\n",
      "6412/6412 [==============================] - 1s 168us/step - loss: 0.8595 - acc: 0.8172\n",
      "Epoch 2/10\n",
      "6412/6412 [==============================] - 0s 75us/step - loss: 0.4026 - acc: 0.8350\n",
      "Epoch 3/10\n",
      "6412/6412 [==============================] - 0s 70us/step - loss: 0.3705 - acc: 0.8426\n",
      "Epoch 4/10\n",
      "6412/6412 [==============================] - 0s 71us/step - loss: 0.3458 - acc: 0.8504\n",
      "Epoch 5/10\n",
      "6412/6412 [==============================] - 0s 74us/step - loss: 0.3233 - acc: 0.8532\n",
      "Epoch 6/10\n",
      "6412/6412 [==============================] - 0s 72us/step - loss: 0.3046 - acc: 0.8637\n",
      "Epoch 7/10\n",
      "6412/6412 [==============================] - 0s 73us/step - loss: 0.2912 - acc: 0.8663\n",
      "Epoch 8/10\n",
      "6412/6412 [==============================] - 0s 74us/step - loss: 0.2807 - acc: 0.8699\n",
      "Epoch 9/10\n",
      "6412/6412 [==============================] - 0s 75us/step - loss: 0.2721 - acc: 0.8724\n",
      "Epoch 10/10\n",
      "6412/6412 [==============================] - 1s 81us/step - loss: 0.2688 - acc: 0.8745\n",
      "2138/2138 [==============================] - 0s 170us/step\n",
      "6486 6486\n",
      "Epoch 1/10\n",
      "4864/4864 [==============================] - 1s 231us/step - loss: 1.0210 - acc: 0.8238\n",
      "Epoch 2/10\n",
      "4864/4864 [==============================] - 0s 74us/step - loss: 0.3772 - acc: 0.8351\n",
      "Epoch 3/10\n",
      "4864/4864 [==============================] - 0s 78us/step - loss: 0.2760 - acc: 0.8598\n",
      "Epoch 4/10\n",
      "4864/4864 [==============================] - 0s 79us/step - loss: 0.2018 - acc: 0.9069\n",
      "Epoch 5/10\n",
      "4864/4864 [==============================] - 0s 76us/step - loss: 0.1601 - acc: 0.9363\n",
      "Epoch 6/10\n",
      "4864/4864 [==============================] - 0s 76us/step - loss: 0.1420 - acc: 0.9385\n",
      "Epoch 7/10\n",
      "4864/4864 [==============================] - 0s 75us/step - loss: 0.1285 - acc: 0.9457\n",
      "Epoch 8/10\n",
      "4864/4864 [==============================] - 0s 88us/step - loss: 0.1163 - acc: 0.9525\n",
      "Epoch 9/10\n",
      "4864/4864 [==============================] - 0s 75us/step - loss: 0.1052 - acc: 0.9636\n",
      "Epoch 10/10\n",
      "4864/4864 [==============================] - 0s 82us/step - loss: 0.0981 - acc: 0.9657\n",
      "1622/1622 [==============================] - 0s 212us/step\n",
      "161784 161784\n",
      "Epoch 1/10\n",
      "121338/121338 [==============================] - 10s 85us/step - loss: 0.3535 - acc: 0.8536\n",
      "Epoch 2/10\n",
      "121338/121338 [==============================] - 12s 103us/step - loss: 0.2388 - acc: 0.9103\n",
      "Epoch 3/10\n",
      "121338/121338 [==============================] - 10s 80us/step - loss: 0.1974 - acc: 0.9375\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121338/121338 [==============================] - 9s 78us/step - loss: 0.1680 - acc: 0.9430\n",
      "Epoch 5/10\n",
      "121338/121338 [==============================] - 9s 76us/step - loss: 0.1571 - acc: 0.9451\n",
      "Epoch 6/10\n",
      "121338/121338 [==============================] - 9s 72us/step - loss: 0.1523 - acc: 0.9465\n",
      "Epoch 7/10\n",
      "121338/121338 [==============================] - 9s 75us/step - loss: 0.1482 - acc: 0.9477\n",
      "Epoch 8/10\n",
      "121338/121338 [==============================] - 10s 82us/step - loss: 0.1448 - acc: 0.9493\n",
      "Epoch 9/10\n",
      "121338/121338 [==============================] - 9s 74us/step - loss: 0.1423 - acc: 0.9498\n",
      "Epoch 10/10\n",
      "121338/121338 [==============================] - 9s 71us/step - loss: 0.1399 - acc: 0.9506\n",
      "40446/40446 [==============================] - 2s 41us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f0afaabf78bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m#if i==\"15\" or i==\"16\":continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-ff108169bb2b>\u001b[0m in \u001b[0;36mcreate_df\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdf_0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mresult\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[0;32m   4968\u001b[0m             )\n\u001b[0;32m   4969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4970\u001b[1;33m         \u001b[0mlocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4971\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "\n",
    "device_names={0:' Aria',\n",
    "1:' D-LinkCam',\n",
    "2:' D-LinkDayCam',\n",
    "3:' D-LinkDoorSensor',\n",
    "4:' D-LinkHomeHub',\n",
    "5:' D-LinkSensor',\n",
    "6:' D-LinkSiren',\n",
    "7:' D-LinkSwitch',\n",
    "8:' D-LinkWaterSensor',\n",
    "9:' EdimaxCam',\n",
    "10:' EdimaxPlug1101W',\n",
    "11:' EdimaxPlug2101W',\n",
    "12:' EdnetCam',\n",
    "13:' EdnetGateway',\n",
    "14:' HomeMaticPlug',\n",
    "15:' HueBridge',\n",
    "16:' HueSwitch',\n",
    "17:' iKettle2',\n",
    "18:' Lightify',\n",
    "19:' MAXGateway',\n",
    "20:' SmarterCoffee',\n",
    "21:' TP-LinkPlugHS100',\n",
    "22:' TP-LinkPlugHS110',\n",
    "23:' WeMoInsightSwitch',\n",
    "24:' WeMoLink',\n",
    "25:' WeMoSwitch',\n",
    "26:' Withings'}\n",
    "\n",
    "devices=[0,\n",
    " 1,\n",
    " 2,\n",
    " 3,\n",
    " 4,\n",
    " 5,\n",
    " 6,\n",
    " 7,\n",
    " 8,\n",
    " 9,\n",
    " 10,\n",
    " 11,\n",
    " 12,\n",
    " 13,\n",
    " 14,\n",
    " 15,\n",
    " 16,\n",
    " 17,\n",
    " 18,\n",
    " 19,\n",
    " 20,\n",
    " 21,\n",
    " 22,\n",
    " 23,\n",
    " 24,\n",
    " 25,\n",
    " 26]\n",
    "\n",
    "result=[]\n",
    "for i in device_names:\n",
    "    if i==\"15\" or i==\"16\":continue\n",
    "    \n",
    "    df=create_df(device_names[i])\n",
    "    x = df.iloc[:,0:25]\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "    y= df['Label'].astype('category')\n",
    "\n",
    "    y=y.cat.codes\n",
    "    y=y.values\n",
    "\n",
    "    temp_y=[]\n",
    "    for j in y:\n",
    "        if int(j)==int(i):\n",
    "            temp_y.append(1)\n",
    "        else:\n",
    "            temp_y.append(0)\n",
    "    y= np.array(temp_y)\n",
    "    print(len(x),len(y))    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,random_state=1)\n",
    "    x_train = x_train.reshape(-1,5,5,1) #(64,64,1)\n",
    "    x_test = x_test.reshape(-1,5,5,1)    #(64,64,1)\n",
    "\n",
    "    #y_train = y_train.reshape(-1,1)    #(64,64,1)\n",
    "    #print(\"x_train shape : \", x_train.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape)\n",
    "    \n",
    "    \n",
    "    # Importing the required Keras modules containing model and layers\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "    # Creating a Sequential Model and adding the layers\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "    model.add(Dense(128, activation=tf.nn.relu))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(27,activation=tf.nn.softmax))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "    print(i)\n",
    "    model.fit(x=x_train,y=y_train, epochs=10)\n",
    "    \n",
    "    score,acc=(model.evaluate(x_test, y_test))\n",
    "    temp=str(i)+\"  =   \"+str(acc)\n",
    "    result.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  =   0.8655578655578655\n",
      "1  =   0.9038444384925872\n",
      "2  =   0.8955139125496877\n",
      "3  =   0.9917456972251493\n",
      "4  =   0.8929756056598228\n",
      "5  =   0.8207700793254824\n",
      "6  =   0.8261851015532259\n",
      "7  =   0.8360875160875161\n",
      "8  =   0.8351242629652175\n",
      "9  =   0.9315476190476191\n",
      "10  =   0.8430930930930931\n",
      "11  =   0.8342719227195458\n",
      "12  =   0.9176470588235294\n",
      "13  =   0.8816651076886897\n",
      "14  =   0.9747225647348952\n",
      "15  =   0.9519853631855796\n"
     ]
    }
   ],
   "source": [
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368 1368\n",
      "17\n",
      "Epoch 1/10\n",
      "1026/1026 [==============================] - 1s 766us/step - loss: 2.5224 - acc: 0.8558\n",
      "Epoch 2/10\n",
      "1026/1026 [==============================] - 0s 83us/step - loss: 0.5196 - acc: 0.9766\n",
      "Epoch 3/10\n",
      "1026/1026 [==============================] - 0s 85us/step - loss: 0.1678 - acc: 0.9766\n",
      "Epoch 4/10\n",
      "1026/1026 [==============================] - 0s 84us/step - loss: 0.1379 - acc: 0.9766\n",
      "Epoch 5/10\n",
      "1026/1026 [==============================] - 0s 84us/step - loss: 0.1206 - acc: 0.9766\n",
      "Epoch 6/10\n",
      "1026/1026 [==============================] - 0s 86us/step - loss: 0.1165 - acc: 0.9766\n",
      "Epoch 7/10\n",
      "1026/1026 [==============================] - 0s 83us/step - loss: 0.1084 - acc: 0.9766\n",
      "Epoch 8/10\n",
      "1026/1026 [==============================] - 0s 84us/step - loss: 0.1044 - acc: 0.9766\n",
      "Epoch 9/10\n",
      "1026/1026 [==============================] - 0s 85us/step - loss: 0.1042 - acc: 0.9766\n",
      "Epoch 10/10\n",
      "1026/1026 [==============================] - 0s 85us/step - loss: 0.0994 - acc: 0.9766\n",
      "342/342 [==============================] - 0s 965us/step\n",
      "44526 44526\n",
      "18\n",
      "Epoch 1/10\n",
      "33394/33394 [==============================] - 3s 98us/step - loss: 0.1444 - acc: 0.9900\n",
      "Epoch 2/10\n",
      "33394/33394 [==============================] - 2s 73us/step - loss: 0.0302 - acc: 0.9951\n",
      "Epoch 3/10\n",
      "33394/33394 [==============================] - 2s 73us/step - loss: 0.0289 - acc: 0.9951\n",
      "Epoch 4/10\n",
      "33394/33394 [==============================] - 2s 74us/step - loss: 0.0281 - acc: 0.9951\n",
      "Epoch 5/10\n",
      "33394/33394 [==============================] - 2s 74us/step - loss: 0.0267 - acc: 0.9951\n",
      "Epoch 6/10\n",
      "33394/33394 [==============================] - 2s 74us/step - loss: 0.0253 - acc: 0.9951\n",
      "Epoch 7/10\n",
      "33394/33394 [==============================] - 2s 74us/step - loss: 0.0251 - acc: 0.9951\n",
      "Epoch 8/10\n",
      "33394/33394 [==============================] - 2s 74us/step - loss: 0.0246 - acc: 0.9951\n",
      "Epoch 9/10\n",
      "33394/33394 [==============================] - 2s 74us/step - loss: 0.0245 - acc: 0.9951\n",
      "Epoch 10/10\n",
      "33394/33394 [==============================] - 2s 74us/step - loss: 0.0243 - acc: 0.9951\n",
      "11132/11132 [==============================] - 1s 65us/step\n",
      "7050 7050\n",
      "19\n",
      "Epoch 1/10\n",
      "5287/5287 [==============================] - 1s 214us/step - loss: 0.6012 - acc: 0.9809\n",
      "Epoch 2/10\n",
      "5287/5287 [==============================] - 0s 75us/step - loss: 0.0125 - acc: 0.9991\n",
      "Epoch 3/10\n",
      "5287/5287 [==============================] - 0s 86us/step - loss: 0.0093 - acc: 0.9991\n",
      "Epoch 4/10\n",
      "5287/5287 [==============================] - 0s 84us/step - loss: 0.0083 - acc: 0.9991\n",
      "Epoch 5/10\n",
      "5287/5287 [==============================] - 1s 132us/step - loss: 0.0074 - acc: 0.9991\n",
      "Epoch 6/10\n",
      "5287/5287 [==============================] - 1s 101us/step - loss: 0.0065 - acc: 0.9991\n",
      "Epoch 7/10\n",
      "5287/5287 [==============================] - 1s 96us/step - loss: 0.0061 - acc: 0.9991\n",
      "Epoch 8/10\n",
      "5287/5287 [==============================] - 1s 105us/step - loss: 0.0053 - acc: 0.9991\n",
      "Epoch 9/10\n",
      "5287/5287 [==============================] - 1s 117us/step - loss: 0.0051 - acc: 0.9991\n",
      "Epoch 10/10\n",
      "5287/5287 [==============================] - 0s 91us/step - loss: 0.0053 - acc: 0.9991\n",
      "1763/1763 [==============================] - 0s 231us/step\n",
      "1452 1452\n",
      "20\n",
      "Epoch 1/10\n",
      "1089/1089 [==============================] - 1s 1ms/step - loss: 2.4379 - acc: 0.8788\n",
      "Epoch 2/10\n",
      "1089/1089 [==============================] - 0s 110us/step - loss: 0.3208 - acc: 0.9954\n",
      "Epoch 3/10\n",
      "1089/1089 [==============================] - 0s 128us/step - loss: 0.0602 - acc: 0.9954\n",
      "Epoch 4/10\n",
      "1089/1089 [==============================] - 0s 127us/step - loss: 0.0472 - acc: 0.9954\n",
      "Epoch 5/10\n",
      "1089/1089 [==============================] - 0s 106us/step - loss: 0.0457 - acc: 0.9954\n",
      "Epoch 6/10\n",
      "1089/1089 [==============================] - ETA: 0s - loss: 0.0413 - acc: 0.995 - 0s 109us/step - loss: 0.0396 - acc: 0.9954\n",
      "Epoch 7/10\n",
      "1089/1089 [==============================] - 0s 127us/step - loss: 0.0365 - acc: 0.9954\n",
      "Epoch 8/10\n",
      "1089/1089 [==============================] - 0s 110us/step - loss: 0.0386 - acc: 0.9954\n",
      "Epoch 9/10\n",
      "1089/1089 [==============================] - 0s 109us/step - loss: 0.0382 - acc: 0.9954\n",
      "Epoch 10/10\n",
      "1089/1089 [==============================] - 0s 113us/step - loss: 0.0350 - acc: 0.9954\n",
      "363/363 [==============================] - 0s 1ms/step\n",
      "8112 8112\n",
      "21\n",
      "Epoch 1/10\n",
      "6084/6084 [==============================] - 1s 218us/step - loss: 0.5841 - acc: 0.9632\n",
      "Epoch 2/10\n",
      "6084/6084 [==============================] - 1s 96us/step - loss: 0.0362 - acc: 0.9952\n",
      "Epoch 3/10\n",
      "6084/6084 [==============================] - 1s 88us/step - loss: 0.0339 - acc: 0.9952\n",
      "Epoch 4/10\n",
      "6084/6084 [==============================] - 1s 91us/step - loss: 0.0323 - acc: 0.9952\n",
      "Epoch 5/10\n",
      "6084/6084 [==============================] - 1s 83us/step - loss: 0.0319 - acc: 0.9952\n",
      "Epoch 6/10\n",
      "6084/6084 [==============================] - 1s 87us/step - loss: 0.0324 - acc: 0.9952\n",
      "Epoch 7/10\n",
      "6084/6084 [==============================] - 0s 80us/step - loss: 0.0312 - acc: 0.9952\n",
      "Epoch 8/10\n",
      "6084/6084 [==============================] - 1s 85us/step - loss: 0.0305 - acc: 0.9952\n",
      "Epoch 9/10\n",
      "6084/6084 [==============================] - 1s 94us/step - loss: 0.0303 - acc: 0.9952\n",
      "Epoch 10/10\n",
      "6084/6084 [==============================] - 1s 88us/step - loss: 0.0308 - acc: 0.9952\n",
      "2028/2028 [==============================] - 0s 204us/step\n",
      "7374 7374\n",
      "22\n",
      "Epoch 1/10\n",
      "5530/5530 [==============================] - 1s 252us/step - loss: 0.8307 - acc: 0.9217\n",
      "Epoch 2/10\n",
      "5530/5530 [==============================] - 0s 78us/step - loss: 0.1843 - acc: 0.9584\n",
      "Epoch 3/10\n",
      "5530/5530 [==============================] - 0s 83us/step - loss: 0.1780 - acc: 0.9584\n",
      "Epoch 4/10\n",
      "5530/5530 [==============================] - 0s 78us/step - loss: 0.1755 - acc: 0.9584\n",
      "Epoch 5/10\n",
      "5530/5530 [==============================] - 0s 82us/step - loss: 0.1731 - acc: 0.9584\n",
      "Epoch 6/10\n",
      "5530/5530 [==============================] - 0s 80us/step - loss: 0.1694 - acc: 0.9584\n",
      "Epoch 7/10\n",
      "5530/5530 [==============================] - 0s 82us/step - loss: 0.1674 - acc: 0.9584\n",
      "Epoch 8/10\n",
      "5530/5530 [==============================] - 0s 79us/step - loss: 0.1666 - acc: 0.9584\n",
      "Epoch 9/10\n",
      "5530/5530 [==============================] - 0s 79us/step - loss: 0.1632 - acc: 0.9584\n",
      "Epoch 10/10\n",
      "5530/5530 [==============================] - 0s 84us/step - loss: 0.1611 - acc: 0.9584\n",
      "1844/1844 [==============================] - 0s 223us/step\n",
      "58632 58632\n",
      "23\n",
      "Epoch 1/10\n",
      "43974/43974 [==============================] - 4s 99us/step - loss: 0.2640 - acc: 0.9477\n",
      "Epoch 2/10\n",
      "43974/43974 [==============================] - 4s 82us/step - loss: 0.1543 - acc: 0.9519\n",
      "Epoch 3/10\n",
      "43974/43974 [==============================] - 3s 79us/step - loss: 0.1449 - acc: 0.9534\n",
      "Epoch 4/10\n",
      "43974/43974 [==============================] - 4s 83us/step - loss: 0.1409 - acc: 0.9537\n",
      "Epoch 5/10\n",
      "43974/43974 [==============================] - 4s 82us/step - loss: 0.1388 - acc: 0.9542\n",
      "Epoch 6/10\n",
      "43974/43974 [==============================] - 4s 82us/step - loss: 0.1375 - acc: 0.9539\n",
      "Epoch 7/10\n",
      "43974/43974 [==============================] - 4s 85us/step - loss: 0.1366 - acc: 0.9541\n",
      "Epoch 8/10\n",
      "43974/43974 [==============================] - 4s 85us/step - loss: 0.1363 - acc: 0.9546\n",
      "Epoch 9/10\n",
      "43974/43974 [==============================] - 4s 86us/step - loss: 0.1350 - acc: 0.9542\n",
      "Epoch 10/10\n",
      "43974/43974 [==============================] - 4s 83us/step - loss: 0.1350 - acc: 0.9544\n",
      "14658/14658 [==============================] - 1s 67us/step\n",
      "65988 65988\n",
      "24\n",
      "Epoch 1/10\n",
      "49491/49491 [==============================] - 6s 113us/step - loss: 0.2174 - acc: 0.9616\n",
      "Epoch 2/10\n",
      "49491/49491 [==============================] - 6s 117us/step - loss: 0.1417 - acc: 0.9647\n",
      "Epoch 3/10\n",
      "49491/49491 [==============================] - 5s 107us/step - loss: 0.1363 - acc: 0.9647\n",
      "Epoch 4/10\n",
      "49491/49491 [==============================] - 5s 99us/step - loss: 0.1295 - acc: 0.9647\n",
      "Epoch 5/10\n",
      "49491/49491 [==============================] - 4s 86us/step - loss: 0.1220 - acc: 0.9647\n",
      "Epoch 6/10\n",
      "49491/49491 [==============================] - 4s 87us/step - loss: 0.1155 - acc: 0.9647\n",
      "Epoch 7/10\n",
      "49491/49491 [==============================] - 4s 90us/step - loss: 0.1095 - acc: 0.9647\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49491/49491 [==============================] - 5s 97us/step - loss: 0.1061 - acc: 0.9651\n",
      "Epoch 9/10\n",
      "49491/49491 [==============================] - 4s 83us/step - loss: 0.1039 - acc: 0.9658\n",
      "Epoch 10/10\n",
      "49491/49491 [==============================] - 4s 88us/step - loss: 0.1022 - acc: 0.9660\n",
      "16497/16497 [==============================] - 1s 72us/step\n",
      "44868 44868\n",
      "25\n",
      "Epoch 1/10\n",
      "33651/33651 [==============================] - 4s 112us/step - loss: 0.1385 - acc: 0.9873\n",
      "Epoch 2/10\n",
      "33651/33651 [==============================] - 3s 86us/step - loss: 0.0344 - acc: 0.9942\n",
      "Epoch 3/10\n",
      "33651/33651 [==============================] - 3s 84us/step - loss: 0.0311 - acc: 0.9942\n",
      "Epoch 4/10\n",
      "33651/33651 [==============================] - 3s 83us/step - loss: 0.0282 - acc: 0.9942\n",
      "Epoch 5/10\n",
      "33651/33651 [==============================] - 3s 85us/step - loss: 0.0258 - acc: 0.9942\n",
      "Epoch 6/10\n",
      "33651/33651 [==============================] - 3s 84us/step - loss: 0.0234 - acc: 0.9942\n",
      "Epoch 7/10\n",
      "33651/33651 [==============================] - 3s 82us/step - loss: 0.0215 - acc: 0.9942\n",
      "Epoch 8/10\n",
      "33651/33651 [==============================] - 3s 83us/step - loss: 0.0208 - acc: 0.9942\n",
      "Epoch 9/10\n",
      "33651/33651 [==============================] - 3s 82us/step - loss: 0.0200 - acc: 0.9942\n",
      "Epoch 10/10\n",
      "33651/33651 [==============================] - 3s 82us/step - loss: 0.0194 - acc: 0.9942\n",
      "11217/11217 [==============================] - 1s 76us/step\n",
      "8292 8292\n",
      "26\n",
      "Epoch 1/10\n",
      "6219/6219 [==============================] - 1s 228us/step - loss: 0.5100 - acc: 0.9887\n",
      "Epoch 2/10\n",
      "6219/6219 [==============================] - 1s 88us/step - loss: 0.0107 - acc: 0.9992\n",
      "Epoch 3/10\n",
      "6219/6219 [==============================] - 1s 80us/step - loss: 0.0088 - acc: 0.9992\n",
      "Epoch 4/10\n",
      "6219/6219 [==============================] - 1s 87us/step - loss: 0.0079 - acc: 0.9992\n",
      "Epoch 5/10\n",
      "6219/6219 [==============================] - 1s 91us/step - loss: 0.0069 - acc: 0.9992\n",
      "Epoch 6/10\n",
      "6219/6219 [==============================] - 1s 90us/step - loss: 0.0061 - acc: 0.9992\n",
      "Epoch 7/10\n",
      "6219/6219 [==============================] - 1s 90us/step - loss: 0.0061 - acc: 0.9992\n",
      "Epoch 8/10\n",
      "6219/6219 [==============================] - 1s 91us/step - loss: 0.0055 - acc: 0.9992\n",
      "Epoch 9/10\n",
      "6219/6219 [==============================] - 1s 90us/step - loss: 0.0053 - acc: 0.9992\n",
      "Epoch 10/10\n",
      "6219/6219 [==============================] - 1s 93us/step - loss: 0.0049 - acc: 0.9992\n",
      "2073/2073 [==============================] - 0s 232us/step\n"
     ]
    }
   ],
   "source": [
    "device_names={16:' HueSwitch',\n",
    "17:' iKettle2',\n",
    "18:' Lightify',\n",
    "19:' MAXGateway',\n",
    "20:' SmarterCoffee',\n",
    "21:' TP-LinkPlugHS100',\n",
    "22:' TP-LinkPlugHS110',\n",
    "23:' WeMoInsightSwitch',\n",
    "24:' WeMoLink',\n",
    "25:' WeMoSwitch',\n",
    "26:' Withings'}\n",
    "\n",
    "devices=[0,\n",
    " 1,\n",
    " 2,\n",
    " 3,\n",
    " 4,\n",
    " 5,\n",
    " 6,\n",
    " 7,\n",
    " 8,\n",
    " 9,\n",
    " 10,\n",
    " 11,\n",
    " 12,\n",
    " 13,\n",
    " 14,\n",
    " 15,\n",
    " 16,\n",
    " 17,\n",
    " 18,\n",
    " 19,\n",
    " 20,\n",
    " 21,\n",
    " 22,\n",
    " 23,\n",
    " 24,\n",
    " 25,\n",
    " 26]\n",
    "\n",
    "result=[]\n",
    "for i in device_names:\n",
    "    if i==15 or i==16 :continue\n",
    "    \n",
    "    df=create_df(device_names[i])\n",
    "    x = df.iloc[:,0:25]\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x = min_max_scaler.fit_transform(x)\n",
    "\n",
    "    y= df['Label'].astype('category')\n",
    "\n",
    "    y=y.cat.codes\n",
    "    y=y.values\n",
    "\n",
    "    temp_y=[]\n",
    "    for j in y:\n",
    "        if int(j)==int(i):\n",
    "            temp_y.append(1)\n",
    "        else:\n",
    "            temp_y.append(0)\n",
    "    y= np.array(temp_y)\n",
    "    print(len(x),len(y))    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.25,random_state=1)\n",
    "    x_train = x_train.reshape(-1,5,5,1) #(64,64,1)\n",
    "    x_test = x_test.reshape(-1,5,5,1)    #(64,64,1)\n",
    "\n",
    "    #y_train = y_train.reshape(-1,1)    #(64,64,1)\n",
    "    #print(\"x_train shape : \", x_train.shape)\n",
    "    #print(\"y_train shape : \", y_train.shape)\n",
    "    \n",
    "    \n",
    "    # Importing the required Keras modules containing model and layers\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "    # Creating a Sequential Model and adding the layers\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "    model.add(Dense(128, activation=tf.nn.relu))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(27,activation=tf.nn.softmax))\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "    print(i)\n",
    "    model.fit(x=x_train,y=y_train, epochs=10)\n",
    "    \n",
    "    score,acc=(model.evaluate(x_test, y_test))\n",
    "    temp=str(i)+\"  =   \"+str(acc)\n",
    "    result.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17  =   0.9590643274853801\n",
      "18  =   0.9955084441250449\n",
      "19  =   1.0\n",
      "20  =   0.9972451790633609\n",
      "21  =   0.997534516765286\n",
      "22  =   0.9479392623435908\n",
      "23  =   0.9523809523809523\n",
      "24  =   0.9678123295144572\n",
      "25  =   0.9934028706480882\n",
      "26  =   0.9995176073323685\n"
     ]
    }
   ],
   "source": [
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
